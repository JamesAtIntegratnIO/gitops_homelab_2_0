{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": { "type": "grafana", "uid": "-- Grafana --" },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "description": "Kratix platform controller metrics — reconciliation, pipelines, work queues, and ArgoCD sync status",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "id": null,
  "links": [],
  "panels": [
    {
      "collapsed": false,
      "gridPos": { "h": 1, "w": 24, "x": 0, "y": 0 },
      "id": 100,
      "title": "Platform Overview",
      "type": "row"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Cumulative count of all controller reconciliation loops. A steadily increasing number is normal — spikes may indicate config changes or resource churn.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null }
            ]
          },
          "mappings": []
        },
        "overrides": []
      },
      "gridPos": { "h": 4, "w": 4, "x": 0, "y": 1 },
      "id": 1,
      "options": {
        "colorMode": "background",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": { "calcs": ["lastNotNull"], "fields": "", "values": false },
        "textMode": "auto"
      },
      "title": "Total Reconciles",
      "type": "stat",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "sum(controller_runtime_reconcile_total{job=~\".*kratix.*\"}) or vector(0)",
          "legendFormat": "",
          "refId": "A",
          "instant": true
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Total controller reconciliation errors. Any value > 0 means a controller failed to reconcile a resource. Check controller logs for root cause.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "red", "value": 1 }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": { "h": 4, "w": 4, "x": 4, "y": 1 },
      "id": 2,
      "options": {
        "colorMode": "background",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": { "calcs": ["lastNotNull"], "fields": "", "values": false },
        "textMode": "auto"
      },
      "title": "Reconcile Errors",
      "type": "stat",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "sum(controller_runtime_reconcile_errors_total{job=~\".*kratix.*\"}) or vector(0)",
          "legendFormat": "",
          "refId": "A",
          "instant": true
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Percentage of reconciliations completing without error. Below 99% warrants investigation; below 90% is critical and likely means promise fulfillment is impaired.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "red", "value": null },
              { "color": "yellow", "value": 90 },
              { "color": "green", "value": 99 }
            ]
          },
          "unit": "percent",
          "decimals": 1
        },
        "overrides": []
      },
      "gridPos": { "h": 4, "w": 4, "x": 8, "y": 1 },
      "id": 3,
      "options": {
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": { "calcs": ["lastNotNull"], "fields": "", "values": false },
        "textMode": "auto"
      },
      "title": "Reconcile Success Rate",
      "type": "stat",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "(sum(controller_runtime_reconcile_total{job=~\".*kratix.*\",result!=\"error\"}) / sum(controller_runtime_reconcile_total{job=~\".*kratix.*\"})) * 100 or vector(100)",
          "legendFormat": "",
          "refId": "A",
          "instant": true
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Whether the Kratix state-reconciler ArgoCD app is synced. OutOfSync means Kratix wrote to the state repo but ArgoCD hasn't applied the changes to the cluster yet.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "red", "value": 1 }
            ]
          },
          "mappings": [
            { "options": { "0": { "text": "Synced", "color": "green" } }, "type": "value" },
            { "options": { "1": { "text": "OutOfSync", "color": "red" } }, "type": "value" }
          ]
        },
        "overrides": []
      },
      "gridPos": { "h": 4, "w": 4, "x": 12, "y": 1 },
      "id": 4,
      "options": {
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": { "calcs": ["lastNotNull"], "fields": "", "values": false },
        "textMode": "auto"
      },
      "title": "State Reconciler Sync",
      "type": "stat",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "argocd_app_info{name=\"kratix-state-reconciler\", sync_status!=\"Synced\"} or vector(0)",
          "legendFormat": "",
          "refId": "A",
          "instant": true
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Count of pipeline pods in Failed state. Failed pipelines mean promise fulfillment is broken for affected resources — check pod logs immediately.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "red", "value": 1 }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": { "h": 4, "w": 4, "x": 16, "y": 1 },
      "id": 5,
      "options": {
        "colorMode": "background",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": { "calcs": ["lastNotNull"], "fields": "", "values": false },
        "textMode": "auto"
      },
      "title": "Failed Pipeline Pods",
      "type": "stat",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "count(kube_pod_status_phase{namespace=\"platform-requests\", phase=\"Failed\"}) or vector(0)",
          "legendFormat": "",
          "refId": "A",
          "instant": true
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Items waiting to be processed across all controller work queues. Sustained high values indicate the controller can't keep up with incoming work and promises may be delayed.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 1 },
              { "color": "red", "value": 5 }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": { "h": 4, "w": 4, "x": 20, "y": 1 },
      "id": 6,
      "options": {
        "colorMode": "background",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": { "calcs": ["lastNotNull"], "fields": "", "values": false },
        "textMode": "auto"
      },
      "title": "Queue Depth",
      "type": "stat",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "sum(workqueue_depth{job=~\".*kratix.*\"}) or vector(0)",
          "legendFormat": "",
          "refId": "A",
          "instant": true
        }
      ]
    },
    {
      "collapsed": false,
      "gridPos": { "h": 1, "w": 24, "x": 0, "y": 5 },
      "id": 101,
      "title": "Pipeline Execution",
      "type": "row"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Tracks pipeline pod lifecycle phases over time. Growing 'Succeeded' count is normal — the cleanup CronJob runs daily at 04:00 to prune completed jobs. 'Failed' or stuck 'Running' pods need immediate attention.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "axisLabel": "",
            "drawStyle": "bars",
            "fillOpacity": 80,
            "lineWidth": 1,
            "pointSize": 5,
            "showPoints": "auto",
            "stacking": { "group": "A", "mode": "normal" }
          }
        },
        "overrides": [
          {
            "matcher": { "id": "byName", "options": "Completed" },
            "properties": [{ "id": "color", "value": { "fixedColor": "green", "mode": "fixed" } }]
          },
          {
            "matcher": { "id": "byName", "options": "Failed" },
            "properties": [{ "id": "color", "value": { "fixedColor": "red", "mode": "fixed" } }]
          },
          {
            "matcher": { "id": "byName", "options": "Running" },
            "properties": [{ "id": "color", "value": { "fixedColor": "blue", "mode": "fixed" } }]
          },
          {
            "matcher": { "id": "byName", "options": "Pending" },
            "properties": [{ "id": "color", "value": { "fixedColor": "yellow", "mode": "fixed" } }]
          }
        ]
      },
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 6 },
      "id": 10,
      "options": {
        "legend": { "calcs": [], "displayMode": "list", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "none" }
      },
      "title": "Pipeline Pod Status Over Time",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "count(kube_pod_status_phase{namespace=\"platform-requests\", phase=\"Succeeded\"}) or vector(0)",
          "legendFormat": "Completed",
          "refId": "A"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "count(kube_pod_status_phase{namespace=\"platform-requests\", phase=\"Failed\"}) or vector(0)",
          "legendFormat": "Failed",
          "refId": "B"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "count(kube_pod_status_phase{namespace=\"platform-requests\", phase=\"Running\"}) or vector(0)",
          "legendFormat": "Running",
          "refId": "C"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "count(kube_pod_status_phase{namespace=\"platform-requests\", phase=\"Pending\"}) or vector(0)",
          "legendFormat": "Pending",
          "refId": "D"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Shows which promises are generating the most pipeline activity. Useful for identifying noisy promises that reconcile too frequently or unexpected reconciliation loops.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "drawStyle": "line",
            "fillOpacity": 10,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "auto"
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 6 },
      "id": 11,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "desc" }
      },
      "title": "Pipeline Pods by Promise",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "count by (label_kratix_io_promise_name) (kube_pod_labels{namespace=\"platform-requests\", label_kratix_io_promise_name!=\"\"})",
          "legendFormat": "{{ label_kratix_io_promise_name }}",
          "refId": "A"
        }
      ]
    },
    {
      "collapsed": false,
      "gridPos": { "h": 1, "w": 24, "x": 0, "y": 14 },
      "id": 102,
      "title": "Controller Reconciliation",
      "type": "row"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Reconciliations per second grouped by outcome. Success and requeue_after are normal. Sustained 'error' results indicate broken resources. High 'requeue' rates mean controllers are retrying due to transient failures.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "drawStyle": "line",
            "fillOpacity": 20,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "auto",
            "stacking": { "group": "A", "mode": "normal" }
          },
          "unit": "ops"
        },
        "overrides": [
          {
            "matcher": { "id": "byName", "options": "success" },
            "properties": [{ "id": "color", "value": { "fixedColor": "green", "mode": "fixed" } }]
          },
          {
            "matcher": { "id": "byName", "options": "error" },
            "properties": [{ "id": "color", "value": { "fixedColor": "red", "mode": "fixed" } }]
          },
          {
            "matcher": { "id": "byName", "options": "requeue" },
            "properties": [{ "id": "color", "value": { "fixedColor": "yellow", "mode": "fixed" } }]
          },
          {
            "matcher": { "id": "byName", "options": "requeue_after" },
            "properties": [{ "id": "color", "value": { "fixedColor": "blue", "mode": "fixed" } }]
          }
        ]
      },
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 15 },
      "id": 20,
      "options": {
        "legend": { "calcs": ["sum"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "none" }
      },
      "title": "Reconcile Rate by Result",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "sum by (result) (rate(controller_runtime_reconcile_total{job=~\".*kratix.*\"}[5m]))",
          "legendFormat": "{{ result }}",
          "refId": "A"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Shows which controllers are most active. Helps identify if a specific controller (e.g. Promise, Work, WorkPlacement) is doing excessive reconciliations, which may indicate a hot resource or feedback loop.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "drawStyle": "line",
            "fillOpacity": 10,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "auto"
          },
          "unit": "ops"
        },
        "overrides": []
      },
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 15 },
      "id": 21,
      "options": {
        "legend": { "calcs": ["sum"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "desc" }
      },
      "title": "Reconcile Rate by Controller",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "sum by (controller) (rate(controller_runtime_reconcile_total{job=~\".*kratix.*\"}[5m])) > 0",
          "legendFormat": "{{ controller }}",
          "refId": "A"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Rate of work items being retried per controller queue. High retry rates indicate controllers are struggling — often due to resource conflicts, API throttling, or transient errors. Correlate with reconcile errors.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "drawStyle": "line",
            "fillOpacity": 10,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "auto"
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 23 },
      "id": 22,
      "options": {
        "legend": { "calcs": ["sum"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "desc" }
      },
      "title": "Work Queue Retries by Controller",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "sum by (name) (rate(workqueue_retries_total{job=~\".*kratix.*\"}[5m])) > 0",
          "legendFormat": "{{ name }}",
          "refId": "A"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "99th percentile time to process a single work item from the queue. Sustained high values may indicate resource contention, slow API calls, or complex reconciliation logic in specific controllers.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "drawStyle": "line",
            "fillOpacity": 10,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "auto"
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 23 },
      "id": 23,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "desc" }
      },
      "title": "Work Queue Processing Time (p99)",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "histogram_quantile(0.99, sum by (name, le) (rate(workqueue_work_duration_seconds_bucket{job=~\".*kratix.*\"}[5m])))",
          "legendFormat": "{{ name }}",
          "refId": "A"
        }
      ]
    },
    {
      "collapsed": false,
      "gridPos": { "h": 1, "w": 24, "x": 0, "y": 31 },
      "id": 103,
      "title": "State Store & ArgoCD Sync",
      "type": "row"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Whether the state-reconciler ArgoCD app is synced with the git state repo. OutOfSync means Kratix wrote resources to git but ArgoCD hasn't applied them to the cluster yet — check ArgoCD for sync errors.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "fixed" },
          "mappings": [
            { "options": { "0": { "text": "OutOfSync", "color": "red" }, "1": { "text": "Synced", "color": "green" } }, "type": "value" }
          ]
        },
        "overrides": []
      },
      "gridPos": { "h": 4, "w": 6, "x": 0, "y": 32 },
      "id": 30,
      "options": {
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": { "calcs": ["lastNotNull"], "fields": "", "values": false },
        "textMode": "value"
      },
      "title": "State Reconciler Sync Status",
      "type": "stat",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "count(argocd_app_info{name=\"kratix-state-reconciler\", sync_status=\"Synced\"}) or vector(0)",
          "legendFormat": "",
          "refId": "A",
          "instant": true
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "ArgoCD health status of the state reconciler. Unhealthy means the Kubernetes resources deployed by Kratix are in a degraded state — check the ArgoCD app for resource-level health details.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "fixed" },
          "mappings": [
            { "options": { "0": { "text": "Unhealthy", "color": "red" }, "1": { "text": "Healthy", "color": "green" } }, "type": "value" }
          ]
        },
        "overrides": []
      },
      "gridPos": { "h": 4, "w": 6, "x": 6, "y": 32 },
      "id": 31,
      "options": {
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": { "calcs": ["lastNotNull"], "fields": "", "values": false },
        "textMode": "value"
      },
      "title": "State Reconciler Health",
      "type": "stat",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "count(argocd_app_info{name=\"kratix-state-reconciler\", health_status=\"Healthy\"}) or vector(0)",
          "legendFormat": "",
          "refId": "A",
          "instant": true
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Cumulative sync operation count for Kratix-managed ArgoCD applications. Correlate with sync duration to identify apps that sync frequently or take unusually long.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "drawStyle": "line",
            "fillOpacity": 10,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "auto"
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 32 },
      "id": 32,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "none" }
      },
      "title": "ArgoCD Sync Duration (Kratix Apps)",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "argocd_app_sync_total{name=~\"kratix.*\", phase=\"Succeeded\"}",
          "legendFormat": "{{ name }}",
          "refId": "A"
        }
      ]
    },
    {
      "collapsed": false,
      "gridPos": { "h": 1, "w": 24, "x": 0, "y": 40 },
      "id": 104,
      "title": "Controller Runtime Health",
      "type": "row"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Reconciliation duration by controller at p50 (median), p95, and p99. Tail latency (p99) reveals problems that averages hide. If p99 is much higher than p50, some reconciliations are getting stuck. Compare controllers to find the slowest.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "drawStyle": "line",
            "fillOpacity": 10,
            "lineWidth": 1,
            "pointSize": 5,
            "showPoints": "never"
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 41 },
      "id": 40,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "desc" }
      },
      "title": "Reconcile Duration (p50 / p95 / p99)",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "histogram_quantile(0.5, sum by (controller, le) (rate(controller_runtime_reconcile_time_seconds_bucket{job=~\".*kratix.*\"}[5m])))",
          "legendFormat": "{{ controller }} p50",
          "refId": "A"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "histogram_quantile(0.95, sum by (controller, le) (rate(controller_runtime_reconcile_time_seconds_bucket{job=~\".*kratix.*\"}[5m])))",
          "legendFormat": "{{ controller }} p95",
          "refId": "B"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "histogram_quantile(0.99, sum by (controller, le) (rate(controller_runtime_reconcile_time_seconds_bucket{job=~\".*kratix.*\"}[5m])))",
          "legendFormat": "{{ controller }} p99",
          "refId": "C"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Real-time queue depth per controller. Shows items waiting to be reconciled. Growing queues mean work is arriving faster than it's being processed — the controller may need more resources or there's a blocking issue.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "drawStyle": "line",
            "fillOpacity": 10,
            "lineWidth": 1,
            "pointSize": 5,
            "showPoints": "never"
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 41 },
      "id": 41,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "desc" }
      },
      "title": "Controller Work Queue Depth",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "workqueue_depth{job=~\".*kratix.*\"}",
          "legendFormat": "{{ name }}",
          "refId": "A"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Controller process memory — RSS is total memory used by the process, Go Alloc is memory actively used by Go objects. If RSS grows steadily while Go Alloc stays flat, the process may have a memory leak or excessive cgo allocation.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "drawStyle": "line",
            "fillOpacity": 10,
            "lineWidth": 1,
            "pointSize": 5,
            "showPoints": "never"
          },
          "unit": "bytes"
        },
        "overrides": []
      },
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 49 },
      "id": 42,
      "options": {
        "legend": { "calcs": ["lastNotNull"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "none" }
      },
      "title": "Controller Memory Usage",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "process_resident_memory_bytes{job=~\".*kratix.*\"}",
          "legendFormat": "Resident Memory",
          "refId": "A"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "go_memstats_alloc_bytes{job=~\".*kratix.*\"}",
          "legendFormat": "Go Alloc",
          "refId": "B"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Active Go goroutines in the controller. Should stabilize at a steady number. A continuously increasing count without plateau indicates a goroutine leak, which will eventually crash the controller with OOM.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "drawStyle": "line",
            "fillOpacity": 10,
            "lineWidth": 1,
            "pointSize": 5,
            "showPoints": "never"
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 49 },
      "id": 43,
      "options": {
        "legend": { "calcs": ["lastNotNull"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "none" }
      },
      "title": "Controller Goroutines",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "go_goroutines{job=~\".*kratix.*\"}",
          "legendFormat": "Goroutines",
          "refId": "A"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Controller CPU usage in cores (1.0 = one full CPU core). Sustained high CPU may indicate reconciliation storms, inefficient controller logic, or excessive API calls. Correlate with reconcile rate to find the cause.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "drawStyle": "line",
            "fillOpacity": 20,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "never"
          },
          "unit": "short",
          "decimals": 3
        },
        "overrides": []
      },
      "gridPos": { "h": 8, "w": 8, "x": 0, "y": 57 },
      "id": 44,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "none" }
      },
      "title": "Controller CPU Usage (cores)",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "rate(process_cpu_seconds_total{job=~\".*kratix.*\"}[5m])",
          "legendFormat": "CPU cores",
          "refId": "A"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Duration of the longest-running work item processor per queue. High values (> 60s) indicate a reconciliation is stuck or taking unusually long — possibly waiting on an external resource, blocked by a lock, or in a retry loop. Critical for detecting silent hangs.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "drawStyle": "line",
            "fillOpacity": 10,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "never"
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": { "h": 8, "w": 8, "x": 8, "y": 57 },
      "id": 45,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "desc" }
      },
      "title": "Longest Running Processor",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "workqueue_longest_running_processor_seconds{job=~\".*kratix.*\"}",
          "legendFormat": "{{ name }}",
          "refId": "A"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "description": "Estimated seconds of unfinished work sitting in the queue. Combines queue depth with processing time to show backlog severity. A rising trend means the controller is falling behind and promises will experience increasing delays.",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisCenteredZero": false,
            "drawStyle": "line",
            "fillOpacity": 10,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "never"
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": { "h": 8, "w": 8, "x": 16, "y": 57 },
      "id": 46,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "desc" }
      },
      "title": "Unfinished Work Backlog",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "expr": "workqueue_unfinished_work_seconds{job=~\".*kratix.*\"}",
          "legendFormat": "{{ name }}",
          "refId": "A"
        }
      ]
    }
  ],
  "refresh": "30s",
  "schemaVersion": 39,
  "tags": ["kratix", "platform"],
  "templating": {
    "list": [
      {
        "current": { "selected": false, "text": "Prometheus", "value": "Prometheus" },
        "hide": 0,
        "includeAll": false,
        "label": "Data Source",
        "multi": false,
        "name": "datasource",
        "options": [],
        "query": "prometheus",
        "queryValue": "",
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "type": "datasource"
      }
    ]
  },
  "time": { "from": "now-6h", "to": "now" },
  "timepicker": {},
  "timezone": "browser",
  "title": "Kratix Platform",
  "uid": "kratix-platform",
  "version": 1
}
