alertmanager:
  enabled: true
  alertmanagerSpec:
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: config-nfs-client
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 5Gi

prometheus:
  service:
    type: ClusterIP
  prometheusSpec:
    enableRemoteWriteReceiver: true
    retention: 15d
    # Mount etcd client certificates for secure etcd scraping
    secrets:
      - etcd-client-cert
    # Disable the behavior that makes {} selector use Helm values
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false
    # Discover ServiceMonitors across all namespaces
    serviceMonitorNamespaceSelector: {}
    serviceMonitorSelector: {}
    # Discover PodMonitors across all namespaces
    podMonitorNamespaceSelector: {}
    podMonitorSelector: {}
    # Discover PrometheusRules across all namespaces
    ruleNamespaceSelector: {}
    ruleSelector: {}
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: config-nfs-client
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 30Gi

# Configure ServiceMonitors for Talos control plane components
kubeControllerManager:
  enabled: true
  endpoints:
    - 10.0.4.101
    - 10.0.4.102
    - 10.0.4.103
  service:
    enabled: true
    port: 10257
    targetPort: 10257
  serviceMonitor:
    enabled: true
    https: true
    insecureSkipVerify: true

kubeScheduler:
  enabled: true
  endpoints:
    - 10.0.4.101
    - 10.0.4.102
    - 10.0.4.103
  service:
    enabled: true
    port: 10259
    targetPort: 10259
  serviceMonitor:
    enabled: true
    https: true
    insecureSkipVerify: true

kubeProxy:
  enabled: true
  endpoints:
    - 10.0.4.101
    - 10.0.4.102
    - 10.0.4.103
  service:
    enabled: true
    port: 10249
    targetPort: 10249

kubeEtcd:
  enabled: true
  # Use selector workaround to auto-populate endpoints from control plane nodes
  # See: https://github.com/siderolabs/talos/discussions/7214
  service:
    enabled: true
    port: 2379  # etcd main port with TLS
    targetPort: 2379
    selector:
      k8s-app: kube-controller-manager  # Reuse controller-manager selector since all CP nodes run same services
  serviceMonitor:
    enabled: true
    scheme: https
    insecureSkipVerify: false
    serverName: localhost
    caFile: /etc/prometheus/secrets/etcd-client-cert/ca.crt
    certFile: /etc/prometheus/secrets/etcd-client-cert/server.crt
    keyFile: /etc/prometheus/secrets/etcd-client-cert/server.key
    # Remove pod label since etcd doesn't run in a pod
    metricRelabelings:
      - action: labeldrop
        regex: pod

grafana:
  defaultDashboardsEnabled: true
  defaultDashboardsTimezone: browser
  admin:
    existingSecret: grafana-admin
    userKey: admin-user
    passwordKey: admin-password
  initChownData:
    enabled: false
  podSecurityContext:
    fsGroup: 1000
  securityContext:
    runAsUser: 1000
    runAsGroup: 1000
  service:
    type: ClusterIP
  persistence:
    enabled: true
    storageClassName: config-nfs-client
    size: 5Gi
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: default
          orgId: 1
          folder: Kubernetes
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default
  dashboards:
    default:
      kubernetes-cluster-monitoring:
        gnetId: 315
        datasource: Prometheus
      node-exporter-full:
        gnetId: 1860
        datasource: Prometheus
  additionalDataSources:
    - name: Loki
      type: loki
      access: proxy
      url: http://loki-gateway.loki.svc.cluster.local

defaultRules:
  rules:
    etcd: true
  # Override the etcdInsufficientMembers alert to properly aggregate across all members
  additionalPrometheusRules:
    - name: etcd-override
      groups:
        - name: etcd
          rules:
            - alert: etcdInsufficientMembers
              annotations:
                description: 'etcd cluster "{{ $labels.job }}": insufficient members ({{ $value }}).'
                summary: etcd cluster has insufficient number of members.
              expr: |
                sum(up{job=~".*etcd.*"} == bool 1) < ((count(up{job=~".*etcd.*"}) + 1) / 2)
              for: 3m
              labels:
                severity: critical

